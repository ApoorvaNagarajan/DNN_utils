{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment17.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApoorvaNagarajan/DNN_utils/blob/master/assignment17/assignment17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRihSTgxAoWW",
        "colab_type": "text"
      },
      "source": [
        "#Importing all python packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCNBjizmixGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f9120e94-5349-460e-9e01-402bc8c0620b"
      },
      "source": [
        "# Ensure latest TensorFlow is installed.\n",
        "!pip install -q tf-nightly-gpu-2.0-preview\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 391.5MB 45kB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 36.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 31.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmjVbfqkjCG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c53c544e-db0e-4940-bf8d-1e0fae78b380"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import tensorflow as tf\n",
        "#tf.enable_eager_execution()\n",
        "\n",
        "import functools\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.python.keras import backend\n",
        "from tensorflow.python.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.0.0-dev20190919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8GraHdilddC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74e57761-7928-4ce6-da07-f039285ca1bc"
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7wH0zJEjTux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import time, math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import numpy as np\n",
        "#import time, math\n",
        "#from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "#import tensorflow as tf\n",
        "#import tensorflow.contrib.eager as tfe\n",
        "\n",
        "#from google.colab import drive\n",
        "#from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ7VUE2sBHid",
        "colab_type": "text"
      },
      "source": [
        "**clone the utility repo created**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCO-8DOo1Kyu",
        "colab_type": "code",
        "outputId": "253b29bd-a1df-411d-ceb8-6bc5ab5ab908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!rm -rf DNN_utils\n",
        "!git clone https://github.com/ApoorvaNagarajan/DNN_utils.git\n",
        "\n",
        "from DNN_utils import tfrecord_utils\n",
        "from DNN_utils import data_transforms as dt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DNN_utils'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/30)\u001b[K\rremote: Counting objects:   6% (2/30)\u001b[K\rremote: Counting objects:  10% (3/30)\u001b[K\rremote: Counting objects:  13% (4/30)\u001b[K\rremote: Counting objects:  16% (5/30)\u001b[K\rremote: Counting objects:  20% (6/30)\u001b[K\rremote: Counting objects:  23% (7/30)\u001b[K\rremote: Counting objects:  26% (8/30)\u001b[K\rremote: Counting objects:  30% (9/30)\u001b[K\rremote: Counting objects:  33% (10/30)\u001b[K\rremote: Counting objects:  36% (11/30)\u001b[K\rremote: Counting objects:  40% (12/30)\u001b[K\rremote: Counting objects:  43% (13/30)\u001b[K\rremote: Counting objects:  46% (14/30)\u001b[K\rremote: Counting objects:  50% (15/30)\u001b[K\rremote: Counting objects:  53% (16/30)\u001b[K\rremote: Counting objects:  56% (17/30)\u001b[K\rremote: Counting objects:  60% (18/30)\u001b[K\rremote: Counting objects:  63% (19/30)\u001b[K\rremote: Counting objects:  66% (20/30)\u001b[K\rremote: Counting objects:  70% (21/30)\u001b[K\rremote: Counting objects:  73% (22/30)\u001b[K\rremote: Counting objects:  76% (23/30)\u001b[K\rremote: Counting objects:  80% (24/30)\u001b[K\rremote: Counting objects:  83% (25/30)\u001b[K\rremote: Counting objects:  86% (26/30)\u001b[K\rremote: Counting objects:  90% (27/30)\u001b[K\rremote: Counting objects:  93% (28/30)\u001b[K\rremote: Counting objects:  96% (29/30)\u001b[K\rremote: Counting objects: 100% (30/30)\u001b[K\rremote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects:   3% (1/30)\u001b[K\rremote: Compressing objects:   6% (2/30)\u001b[K\rremote: Compressing objects:  10% (3/30)\u001b[K\rremote: Compressing objects:  13% (4/30)\u001b[K\rremote: Compressing objects:  16% (5/30)\u001b[K\rremote: Compressing objects:  20% (6/30)\u001b[K\rremote: Compressing objects:  23% (7/30)\u001b[K\rremote: Compressing objects:  26% (8/30)\u001b[K\rremote: Compressing objects:  30% (9/30)\u001b[K\rremote: Compressing objects:  33% (10/30)\u001b[K\rremote: Compressing objects:  36% (11/30)\u001b[K\rremote: Compressing objects:  40% (12/30)\u001b[K\rremote: Compressing objects:  43% (13/30)\u001b[K\rremote: Compressing objects:  46% (14/30)\u001b[K\rremote: Compressing objects:  50% (15/30)\u001b[K\rremote: Compressing objects:  53% (16/30)\u001b[K\rremote: Compressing objects:  56% (17/30)\u001b[K\rremote: Compressing objects:  60% (18/30)\u001b[K\rremote: Compressing objects:  63% (19/30)\u001b[K\rremote: Compressing objects:  66% (20/30)\u001b[K\rremote: Compressing objects:  70% (21/30)\u001b[K\rremote: Compressing objects:  73% (22/30)\u001b[K\rremote: Compressing objects:  76% (23/30)\u001b[K\rremote: Compressing objects:  80% (24/30)\u001b[K\rremote: Compressing objects:  83% (25/30)\u001b[K\rremote: Compressing objects:  86% (26/30)\u001b[K\rremote: Compressing objects:  90% (27/30)\u001b[K\rremote: Compressing objects:  93% (28/30)\u001b[K\rremote: Compressing objects:  96% (29/30)\u001b[K\rremote: Compressing objects: 100% (30/30)\u001b[K\rremote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 96 (delta 13), reused 0 (delta 0), pack-reused 66\u001b[K\n",
            "Unpacking objects: 100% (96/96), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TxmEHgFBN6t",
        "colab_type": "text"
      },
      "source": [
        "**Mount google drive to fetch the CIFAR dataset stored in tfRecord format**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3n4tncNyTJ1",
        "colab_type": "code",
        "outputId": "40663a15-cd54-43d8-ac03-8c99f11ec27e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCNNonHjBrPa",
        "colab_type": "text"
      },
      "source": [
        "**Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "BATCH_SIZE = 512 #@param {type:\"number\"}\n",
        "EPOCHS = 2 #@param {type:\"number\"}\n",
        "MOMENTUM = 0.9 #@param {type:\"number\"}\n",
        "LEARNING_RATE = 0.4 #@param {type:\"number\"}\n",
        "WEIGHT_DECAY = 5e-4 #@param {type:\"number\"}\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZDXvqFqBG8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Configuration\n",
        "\n",
        "NUM_CLASSES = 10 \n",
        "IMG_SHAPE=[32, 32, 3]\n",
        "NUM_TRAIN_IMG = 50000\n",
        "NUM_TEST_IMG = 10000\n",
        "BATCHES_PER_EPOCH = NUM_TRAIN_IMG//BATCH_SIZE\n",
        "VALIDATION_STEPS = NUM_TEST_IMG//BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-ymW9bYBjuA",
        "colab_type": "text"
      },
      "source": [
        "#Load tfRecord format CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfrecord_utils.convert_to_tfRecord('CIFAR10',trainFile='/content/drive/My Drive/datasets/cifarTfTrain.tfrecords', testFile='/content/drive/My Drive/datasets/cifarTfTest.tfrecords')\n",
        "#train_x, train_y = tfrecord_utils.parse_tfRecord('/content/drive/My Drive/datasets/cifarTfTrain.tfrecords', NUM_TRAIN_IMG, BATCH_SIZE, IMG_SHAPE, NUM_CLASSES)\n",
        "#test_x, test_y = tfrecord_utils.parse_tfRecord('/content/drive/My Drive/datasets/cifarTfTest.tfrecords', NUM_TEST_IMG, BATCH_SIZE, IMG_SHAPE, NUM_CLASSES)\n",
        "train_set = tfrecord_utils.get_dataset('/content/drive/My Drive/datasets/cifarTfTrain.tfrecords',IMG_SHAPE)\n",
        "test_set = tfrecord_utils.get_dataset('/content/drive/My Drive/datasets/cifarTfTest.tfrecords',IMG_SHAPE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_5NThI0Bwdd",
        "colab_type": "text"
      },
      "source": [
        "#Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRe78gUcg2JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
        "  fan = np.prod(shape[:-1])\n",
        "  bound = 1 / math.sqrt(fan)\n",
        "  return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9ejoe7ffYfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBN(tf.keras.Model):\n",
        "  def __init__(self, c_out):\n",
        "    super().__init__()\n",
        "    self.conv = tf.keras.layers.Conv2D(filters=c_out, kernel_size=3, padding=\"SAME\", kernel_initializer=init_pytorch, use_bias=False)\n",
        "    self.bn = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.nn.relu(self.bn(self.conv(inputs)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnm9F8eXfZSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlk(tf.keras.Model):\n",
        "  def __init__(self, c_out, pool, res = False):\n",
        "    super().__init__()\n",
        "    self.conv_bn = ConvBN(c_out)\n",
        "    self.pool = pool\n",
        "    self.res = res\n",
        "    if self.res:\n",
        "      self.res1 = ConvBN(c_out)\n",
        "      self.res2 = ConvBN(c_out)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    h = self.pool(self.conv_bn(inputs))\n",
        "    if self.res:\n",
        "      h = h + self.res2(self.res1(h))\n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFrEx728fcps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DavidNet(tf.keras.Model):\n",
        "  def __init__(self, c=64, weight=0.125):\n",
        "    super().__init__()\n",
        "    pool = tf.keras.layers.MaxPooling2D()\n",
        "    self.init_conv_bn = ConvBN(c)\n",
        "    self.blk1 = ResBlk(c*2, pool, res = True)\n",
        "    self.blk2 = ResBlk(c*4, pool)\n",
        "    self.blk3 = ResBlk(c*8, pool, res = True)\n",
        "    self.pool = tf.keras.layers.GlobalMaxPool2D()\n",
        "    self.linear = tf.keras.layers.Dense(10, kernel_initializer=init_pytorch, use_bias=False)\n",
        "    self.weight = weight\n",
        "\n",
        "  def call(self, inputs):\n",
        "    h = self.pool(self.blk3(self.blk2(self.blk1(self.init_conv_bn(inputs)))))\n",
        "    h = self.linear(h) * self.weight\n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXjqZr0RB4R0",
        "colab_type": "text"
      },
      "source": [
        "#Create network and run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DavidNet()\n",
        "\n",
        "#lr_schedule = lambda t: np.interp([t], [0, (EPOCHS+1)//5, EPOCHS], [0, LEARNING_RATE, 0])[0]\n",
        "#lr_func = lambda: lr_schedule(EPOCHS)/BATCH_SIZE\n",
        "#opt = tf.train.MomentumOptimizer(lr_func, momentum=MOMENTUM, use_nesterov=True)\n",
        "data_aug = lambda x, y: (dt.random_pad_crop(dt.randomFlip(dt.cutOut(dt.rotate(x, 10),8,8,0)), 4),y)\n",
        "#data_aug = lambda x, y: (tf.image.random_flip_left_right(tf.random_crop(x, [32, 32, 3])), y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXNkuzm1-3V_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import IPython.display as display\n",
        "#import matplotlib.pyplot as plt\n",
        "#import numpy as np\n",
        "#% matplotlib inline\n",
        "\n",
        "#for parsed_record in train_set.take(10):\n",
        "#  print(repr(parsed_record))\n",
        "\n",
        "#for record in train_set.take(10):\n",
        "#  print('here')\n",
        "#  plt.rcParams['figure.figsize'] = (1,1)\n",
        "#  f, ax = plt.subplots(1, 1)\n",
        "#  ax.set_xticks([])\n",
        "#  ax.set_yticks([])\n",
        "#  ax.imshow(record[0].numpy().reshape(32,32,3).astype('int32'))\n",
        "#  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40smoLFiEfKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir=\"logs/profile/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = 3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccl864hMhULH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='SGD',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QnWF3Q2hZ4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "e591d2e3-59f8-473b-fa1b-17979f7ad762"
      },
      "source": [
        "train_set = train_set.repeat()\n",
        "train_set_aug = train_set.map(data_aug).shuffle(NUM_TRAIN_IMG).batch(BATCH_SIZE)\n",
        "test_set = test_set.repeat()\n",
        "test_set = test_set.batch(BATCH_SIZE)\n",
        "\n",
        "model.fit(train_set_aug,\n",
        "          steps_per_epoch=BATCHES_PER_EPOCH,\n",
        "          epochs=EPOCHS, \n",
        "          callbacks=[tensorboard_callback],\n",
        "          validation_data = test_set,\n",
        "          validation_steps = VALIDATION_STEPS)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 97 steps, validate for 19 steps\n",
            "Epoch 1/2\n",
            "97/97 [==============================] - 141s 1s/step - loss: 390.7198 - accuracy: 0.9897 - val_loss: 392.0052 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "97/97 [==============================] - 97s 999ms/step - loss: 370.7580 - accuracy: 1.0000 - val_loss: 383.3436 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0f80838b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOq1KeisWu6a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5fec419-cb1f-4a60-ca45-f5af9ddcc996"
      },
      "source": [
        "!tar -zcvf logs.tar.gz logs/profile/"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logs/profile/\n",
            "logs/profile/20190919-193453/\n",
            "logs/profile/20190919-193453/train/\n",
            "logs/profile/20190919-193453/train/plugins/\n",
            "logs/profile/20190919-193453/train/plugins/profile/\n",
            "logs/profile/20190919-193453/train/plugins/profile/2019-09-19_19-36-24/\n",
            "logs/profile/20190919-193453/train/plugins/profile/2019-09-19_19-36-24/local.trace\n",
            "logs/profile/20190919-193453/train/events.out.tfevents.1568921784.09eb1ba4bc1a.profile-empty\n",
            "logs/profile/20190919-193453/train/events.out.tfevents.1568921739.09eb1ba4bc1a.118.15510.v2\n",
            "logs/profile/20190919-194612/\n",
            "logs/profile/20190919-194612/train/\n",
            "logs/profile/20190919-194612/train/plugins/\n",
            "logs/profile/20190919-194612/train/plugins/profile/\n",
            "logs/profile/20190919-194612/train/plugins/profile/2019-09-19_19-47-46/\n",
            "logs/profile/20190919-194612/train/plugins/profile/2019-09-19_19-47-46/local.trace\n",
            "logs/profile/20190919-194612/train/events.out.tfevents.1568922420.09eb1ba4bc1a.118.28825.v2\n",
            "logs/profile/20190919-194612/train/events.out.tfevents.1568922466.09eb1ba4bc1a.profile-empty\n",
            "logs/profile/20190919-194612/validation/\n",
            "logs/profile/20190919-194612/validation/events.out.tfevents.1568922517.09eb1ba4bc1a.118.31237.v2\n",
            "logs/profile/20190919-195021/\n",
            "logs/profile/20190919-195021/train/\n",
            "logs/profile/20190919-195021/train/plugins/\n",
            "logs/profile/20190919-195021/train/plugins/profile/\n",
            "logs/profile/20190919-195021/train/plugins/profile/2019-09-19_19-51-59/\n",
            "logs/profile/20190919-195021/train/plugins/profile/2019-09-19_19-51-59/local.trace\n",
            "logs/profile/20190919-195021/train/events.out.tfevents.1568922719.09eb1ba4bc1a.profile-empty\n",
            "logs/profile/20190919-195021/train/events.out.tfevents.1568922672.09eb1ba4bc1a.118.34219.v2\n",
            "logs/profile/20190919-195021/validation/\n",
            "logs/profile/20190919-195021/validation/events.out.tfevents.1568922813.09eb1ba4bc1a.118.36628.v2\n",
            "logs/profile/20190919-194251/\n",
            "logs/profile/20190919-194251/train/\n",
            "logs/profile/20190919-194251/train/events.out.tfevents.1568922266.09eb1ba4bc1a.profile-empty\n",
            "logs/profile/20190919-194251/train/plugins/\n",
            "logs/profile/20190919-194251/train/plugins/profile/\n",
            "logs/profile/20190919-194251/train/plugins/profile/2019-09-19_19-44-26/\n",
            "logs/profile/20190919-194251/train/plugins/profile/2019-09-19_19-44-26/local.trace\n",
            "logs/profile/20190919-194251/train/events.out.tfevents.1568922220.09eb1ba4bc1a.118.23850.v2\n",
            "logs/profile/20190919-194251/validation/\n",
            "logs/profile/20190919-194251/validation/events.out.tfevents.1568922294.09eb1ba4bc1a.118.25919.v2\n",
            "logs/profile/20190919-193957/\n",
            "logs/profile/20190919-193957/train/\n",
            "logs/profile/20190919-193957/train/plugins/\n",
            "logs/profile/20190919-193957/train/plugins/profile/\n",
            "logs/profile/20190919-193957/train/plugins/profile/2019-09-19_19-41-31/\n",
            "logs/profile/20190919-193957/train/plugins/profile/2019-09-19_19-41-31/local.trace\n",
            "logs/profile/20190919-193957/train/events.out.tfevents.1568922091.09eb1ba4bc1a.profile-empty\n",
            "logs/profile/20190919-193957/train/events.out.tfevents.1568922046.09eb1ba4bc1a.118.20058.v2\n",
            "logs/profile/20190919-191959/\n",
            "logs/profile/20190919-191959/train/\n",
            "logs/profile/20190919-191959/train/events.out.tfevents.1568920849.09eb1ba4bc1a.118.1625.v2\n",
            "logs/profile/20190919-191959/train/events.out.tfevents.1568921241.09eb1ba4bc1a.118.6384.v2\n",
            "logs/profile/20190919-191959/train/plugins/\n",
            "logs/profile/20190919-191959/train/plugins/profile/\n",
            "logs/profile/20190919-191959/train/plugins/profile/2019-09-19_19-21-40/\n",
            "logs/profile/20190919-191959/train/plugins/profile/2019-09-19_19-21-40/local.trace\n",
            "logs/profile/20190919-191959/train/plugins/profile/2019-09-19_19-28-06/\n",
            "logs/profile/20190919-191959/train/plugins/profile/2019-09-19_19-28-06/local.trace\n",
            "logs/profile/20190919-191959/train/events.out.tfevents.1568920900.09eb1ba4bc1a.profile-empty\n",
            "logs/profile/20190919-192945/\n",
            "logs/profile/20190919-192945/train/\n",
            "logs/profile/20190919-192945/train/plugins/\n",
            "logs/profile/20190919-192945/train/plugins/profile/\n",
            "logs/profile/20190919-192945/train/plugins/profile/2019-09-19_19-31-15/\n",
            "logs/profile/20190919-192945/train/plugins/profile/2019-09-19_19-31-15/local.trace\n",
            "logs/profile/20190919-192945/train/events.out.tfevents.1568921430.09eb1ba4bc1a.118.10925.v2\n",
            "logs/profile/20190919-192945/train/events.out.tfevents.1568921475.09eb1ba4bc1a.profile-empty\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}