# -*- coding: utf-8 -*-
"""tfRecord_utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UvhvLJnHwxib38Kxt2CbrMr1PzwiybLV

#Importing all python packages
"""

import keras
from keras.datasets import cifar10
import tensorflow as tf
from keras import backend as k
import sys
from google.colab import drive
from google.colab import files
import os
import functools


#import tensorflow.contrib.eager as tfe
#tf.enable_eager_execution()

"""#Utility functions"""

def _int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))
  
def _bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

"""#Convert to tfrecord dataset"""

def convert_to_tfRecord(dataset, trainFile=None, testFile=None):
  
  trainExist = os.path.exists(trainFile)
  testExist = os.path.exists(testFile)
  
  if(dataset == 'CIFAR10'):   
    
    if(((trainFile != None) and (False == trainExist)) or ((testFile != None) and (False == testExist))):
      print('downloading')
      (x_train, y_train), (x_test, y_test) = cifar10.load_data()
  
            
    if((trainFile != None) and (False == trainExist)):
      writerTrain = tf.python_io.TFRecordWriter(trainFile)
      for i in range(len(x_train)):
          # Create a feature
          feature = {
              'image': _bytes_feature(x_train[i].tostring()),
              'label': _int64_feature(y_train[i])
          }
          # Create an example protocol buffer
          example = tf.train.Example(features=tf.train.Features(feature=feature))

          # Serialize to string and write on the file
          writerTrain.write(example.SerializeToString())
      writerTrain.close()
      sys.stdout.flush()
          
      
    if((testFile != None) and (False == testExist)):
      writerTest = tf.python_io.TFRecordWriter(testFile)
      for i in range(len(x_test)):
          # Create a feature
          feature = {
              'image': _bytes_feature(x_test[i].tostring()),
              'label': _int64_feature(y_test[i])
          }
          # Create an example protocol buffer
          example = tf.train.Example(features=tf.train.Features(feature=feature))

          # Serialize to string and write on the file
          writerTest.write(example.SerializeToString())
      writerTest.close()
      sys.stdout.flush()          
    
   
  else:
    print('Not supported')

"""#tfrecord file parse function"""

def _parse_image_function(example_proto,img_shape):
  
  
  # Create a dictionary describing the features.
  image_feature_description = {
        "image": tf.io.FixedLenFeature([], tf.string),
        "label": tf.io.FixedLenFeature([], tf.int64)
  }

  # Parse the input tf.Example proto using the dictionary above.
  example = tf.parse_single_example(example_proto, image_feature_description)
  image = tf.reshape(tf.decode_raw(example["image"], tf.uint8),img_shape)
  image = tf.cast(image, tf.float32)
  label = tf.cast(example["label"], tf.int32)
  
  return image, label



def parse_tfRecord(fileName, num_img, batch_size, shape, num_classes):
  
  image_dataset = tf.data.TFRecordDataset(fileName)
  
  image_dataset = image_dataset.map(functools.partial(_parse_image_function,img_shape=shape))
          
  # This dataset will go on forever
  image_dataset = image_dataset.repeat()

  # Set the number of datapoints you want to load and shuffle 
  image_dataset = image_dataset.shuffle(num_img)

  # Set the batchsize
  image_dataset = image_dataset.batch(batch_size)

  # Create an iterator
  iterator = image_dataset.make_one_shot_iterator()

  # Create your tf representation of the iterator
  image, label = iterator.get_next()

  # Bring your picture back in shape
  #image = tf.reshape(image, img_shape)

  # Create a one hot array for your labels
  label = tf.one_hot(label, num_classes)

  return image, label

"""#Get TFRecordDataset from tfRecord file"""

def get_dataset(fileName,shape):
  
  image_dataset = tf.data.TFRecordDataset(fileName)
  
  image_dataset = image_dataset.map(functools.partial(_parse_image_function,img_shape=shape))
          
  return image_dataset

